# Super Resolution Training Framework

ê¹”ë”í•˜ê³  ëª¨ë“ˆí™”ëœ Super Resolution ëª¨ë¸ í•™ìŠµ í”„ë ˆì„ì›Œí¬ì…ë‹ˆë‹¤.

## ğŸ“ í”„ë¡œì íŠ¸ êµ¬ì¡°

```
Experiments/
â”œâ”€â”€ data/                 # ë°ì´í„°ì…‹ (DIV2K)
â”œâ”€â”€ results/              # í•™ìŠµ ê²°ê³¼ë¬¼ë“¤
â”œâ”€â”€ test_div2k.ipynb     # ë°ì´í„°ì…‹ í…ŒìŠ¤íŠ¸ ë…¸íŠ¸ë¶
â”œâ”€â”€ dataset.py           # SR ë°ì´í„°ì…‹ ë¡œë”
â”œâ”€â”€ model_loader.py      # ëª¨ë¸ ë¡œë”
â”œâ”€â”€ engine.py            # í•™ìŠµ/í‰ê°€ ì—”ì§„
â”œâ”€â”€ utils.py             # ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜ë“¤
â”œâ”€â”€ config.py            # ì„¤ì • ê´€ë¦¬
â”œâ”€â”€ train.py             # ë©”ì¸ í•™ìŠµ ìŠ¤í¬ë¦½íŠ¸
â””â”€â”€ README.md            # ì‚¬ìš© ì„¤ëª…ì„œ
```

## ğŸš€ ë¹ ë¥¸ ì‹œì‘

### 1. ê¸°ë³¸ EDSR ëª¨ë¸ í•™ìŠµ
```bash
python train.py --model EDSR --scale 2 --epochs 50
```

### 2. RCAN ëª¨ë¸ë¡œ 4ë°° í™•ëŒ€ í•™ìŠµ
```bash
python train.py --model RCAN --scale 4 --batch-size 8 --epochs 100
```

### 3. ì»¤ìŠ¤í…€ ì„¤ì •ìœ¼ë¡œ í•™ìŠµ
```bash
python train.py \
    --model EDSR \
    --scale 2 \
    --batch-size 16 \
    --epochs 200 \
    --lr 1e-5 \
    --optimizer AdamW \
    --scheduler CosineAnnealingLR \
    --loss L1 \
    --experiment-name "EDSR_experiment_v1"
```

### 4. í›ˆë ¨ ì¬ê°œ
```bash
python train.py --resume-from ./results/EDSR_x2_20231201_120000/checkpoints/last.pth
```

## âš™ï¸ ì£¼ìš” ë§¤ê°œë³€ìˆ˜

### ëª¨ë¸ ê´€ë ¨
- `--model`: ëª¨ë¸ ì¢…ë¥˜ (EDSR, RCAN, ESRGAN, SwinIR)
- `--scale`: í™•ëŒ€ ë¹„ìœ¨ (2, 3, 4, 8)
- `--model-params`: JSON í˜•íƒœì˜ ëª¨ë¸ íŠ¹ìˆ˜ íŒŒë¼ë¯¸í„°

### ë°ì´í„° ê´€ë ¨
- `--data-path`: ë°ì´í„°ì…‹ ê²½ë¡œ (ê¸°ë³¸: ./data/DV2K)
- `--patch-size`: HR íŒ¨ì¹˜ í¬ê¸° (ê¸°ë³¸: 96)
- `--batch-size`: ë°°ì¹˜ í¬ê¸° (ê¸°ë³¸: 16)
- `--num-workers`: ë°ì´í„° ë¡œë” ì›Œì»¤ ìˆ˜ (ê¸°ë³¸: 0)

### í•™ìŠµ ê´€ë ¨
- `--epochs`: í•™ìŠµ ì—í¬í¬ ìˆ˜ (ê¸°ë³¸: 100)
- `--lr`: í•™ìŠµë¥  (ê¸°ë³¸: 1e-4)
- `--weight-decay`: ê°€ì¤‘ì¹˜ ê°ì‡  (ê¸°ë³¸: 1e-4)
- `--loss`: ì†ì‹¤ í•¨ìˆ˜ (L1, L2, MSE, Huber)

### ì˜µí‹°ë§ˆì´ì € ê´€ë ¨
- `--optimizer`: ì˜µí‹°ë§ˆì´ì € (Adam, AdamW, SGD)
- `--scheduler`: ìŠ¤ì¼€ì¤„ëŸ¬ (CosineAnnealingLR, StepLR, MultiStepLR, None)

### ê¸°íƒ€
- `--device`: ë””ë°”ì´ìŠ¤ (auto, cpu, cuda)
- `--experiment-name`: ì‹¤í—˜ ì´ë¦„
- `--save-every`: ì²´í¬í¬ì¸íŠ¸ ì €ì¥ ì£¼ê¸° (ê¸°ë³¸: 10 ì—í¬í¬)
- `--eval-every`: í‰ê°€ ì£¼ê¸° (ê¸°ë³¸: 1 ì—í¬í¬)

## ğŸ“Š ì§€ì›ë˜ëŠ” ëª¨ë¸

### 1. EDSR (Enhanced Deep Residual Networks)
```bash
python train.py --model EDSR --scale 2
```

**ê¸°ë³¸ íŒŒë¼ë¯¸í„°:**
- n_colors: 3
- n_feats: 64
- kernel_size: 3
- n_resblocks: 16
- res_scale: 1.0

### 2. RCAN (Residual Channel Attention Networks)
```bash
python train.py --model RCAN --scale 2
```

**ê¸°ë³¸ íŒŒë¼ë¯¸í„°:**
- n_colors: 3
- n_feats: 64
- kernel_size: 3
- n_resblocks: 20

### 3. ì»¤ìŠ¤í…€ ëª¨ë¸ íŒŒë¼ë¯¸í„°
```bash
python train.py \
    --model EDSR \
    --model-params '{"n_feats": 128, "n_resblocks": 32}'
```

## ğŸ“ˆ í•™ìŠµ ëª¨ë‹ˆí„°ë§

### 1. ë¡œê·¸ í™•ì¸
```bash
tail -f ./results/EDSR_x2_20231201_120000/logs/training.log
```

### 2. ë©”íŠ¸ë¦­ í™•ì¸
í•™ìŠµ ì™„ë£Œ í›„ ë‹¤ìŒ íŒŒì¼ë“¤ì´ ìƒì„±ë©ë‹ˆë‹¤:
- `metrics.csv`: ì—í¬í¬ë³„ ë©”íŠ¸ë¦­ ë°ì´í„°
- `training_curves.png`: í•™ìŠµ ê³¡ì„  ê·¸ë˜í”„
- `config.json`: ì‚¬ìš©ëœ ì„¤ì •

### 3. ìƒ˜í”Œ ì´ë¯¸ì§€ í™•ì¸
`./results/{experiment}/images/` í´ë”ì—ì„œ 10 ì—í¬í¬ë§ˆë‹¤ ìƒì„±ë˜ëŠ” ìƒ˜í”Œ ì´ë¯¸ì§€ë“¤ì„ í™•ì¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

## ğŸ”§ ë¬¸ì œ í•´ê²°

### 1. CUDA ë©”ëª¨ë¦¬ ë¶€ì¡±
```bash
# ë°°ì¹˜ í¬ê¸° ê°ì†Œ
python train.py --batch-size 8

# íŒ¨ì¹˜ í¬ê¸° ê°ì†Œ
python train.py --patch-size 64
```

### 2. Windows í™˜ê²½ì—ì„œ multiprocessing ì˜¤ë¥˜
```bash
# num_workersë¥¼ 0ìœ¼ë¡œ ì„¤ì • (ê¸°ë³¸ê°’)
python train.py --num-workers 0
```

### 3. ë°ì´í„°ì…‹ ê²½ë¡œ ë¬¸ì œ
```bash
# ì ˆëŒ€ ê²½ë¡œ ì‚¬ìš©
python train.py --data-path "C:/path/to/your/DIV2K"
```

## ğŸ“ ì‚¬ìš© ì˜ˆì‹œ

### ì‹¤í—˜ 1: ê¸°ë³¸ EDSR í•™ìŠµ
```bash
python train.py \
    --model EDSR \
    --scale 2 \
    --epochs 100 \
    --experiment-name "EDSR_baseline"
```

### ì‹¤í—˜ 2: í° RCAN ëª¨ë¸ í•™ìŠµ
```bash
python train.py \
    --model RCAN \
    --scale 4 \
    --batch-size 8 \
    --epochs 200 \
    --lr 5e-5 \
    --model-params '{"n_feats": 128}' \
    --experiment-name "RCAN_large_x4"
```

### ì‹¤í—˜ 3: ë¹ ë¥¸ í”„ë¡œí† íƒ€ì´í•‘
```bash
python train.py \
    --model EDSR \
    --epochs 10 \
    --eval-every 2 \
    --save-every 5 \
    --experiment-name "quick_test"
```

## ğŸ“‚ ê²°ê³¼ë¬¼ êµ¬ì¡°

í•™ìŠµ ì™„ë£Œ í›„ ë‹¤ìŒê³¼ ê°™ì€ êµ¬ì¡°ë¡œ ê²°ê³¼ë¬¼ì´ ì €ì¥ë©ë‹ˆë‹¤:

```
results/EDSR_x2_20231201_120000/
â”œâ”€â”€ checkpoints/
â”‚   â”œâ”€â”€ best.pth          # ìµœê³  ì„±ëŠ¥ ëª¨ë¸
â”‚   â”œâ”€â”€ last.pth          # ë§ˆì§€ë§‰ ì—í¬í¬ ëª¨ë¸
â”‚   â””â”€â”€ epoch_*.pth       # ì •ê¸° ì²´í¬í¬ì¸íŠ¸
â”œâ”€â”€ images/
â”‚   â””â”€â”€ samples_epoch_*.png  # ìƒ˜í”Œ ì´ë¯¸ì§€ë“¤
â”œâ”€â”€ logs/
â”‚   â””â”€â”€ training.log      # í•™ìŠµ ë¡œê·¸
â”œâ”€â”€ config.json           # ì‚¬ìš©ëœ ì„¤ì •
â”œâ”€â”€ metrics.csv           # ë©”íŠ¸ë¦­ ë°ì´í„°
â””â”€â”€ training_curves.png   # í•™ìŠµ ê³¡ì„ 
```

## ğŸ”„ ëª¨ë¸ ë¡œë”© ë° ì¶”ë¡ 

```python
import torch
from model_loader import create_model
from utils import load_model

# ëª¨ë¸ ìƒì„±
model = create_model('EDSR', scale=2)

# ì²´í¬í¬ì¸íŠ¸ ë¡œë“œ
load_model('./results/EDSR_x2_20231201_120000/checkpoints/best.pth', model)

# ì¶”ë¡  ëª¨ë“œ
model.eval()
with torch.no_grad():
    sr_img = model(lr_img)
```

## ğŸ†˜ ë„ì›€ë§

ëª¨ë“  ì‚¬ìš© ê°€ëŠ¥í•œ ì˜µì…˜ í™•ì¸:
```bash
python train.py --help
```

## ğŸ“Š ì„±ëŠ¥ ë©”íŠ¸ë¦­

ì´ í”„ë ˆì„ì›Œí¬ëŠ” ë‹¤ìŒ ë©”íŠ¸ë¦­ë“¤ì„ ìë™ìœ¼ë¡œ ê³„ì‚°í•©ë‹ˆë‹¤:
- **Loss**: í•™ìŠµ ì†ì‹¤ (L1, L2, MSE, Huber)
- **PSNR**: Peak Signal-to-Noise Ratio
- **SSIM**: Structural Similarity Index

## ğŸ¯ Best Practices

1. **ì‹œì‘ì€ ì‘ì€ ëª¨ë¸ê³¼ ì§§ì€ ì—í¬í¬ë¡œ**: íŒŒì´í”„ë¼ì¸ì´ ì •ìƒ ì‘ë™í•˜ëŠ”ì§€ í™•ì¸
2. **ë°°ì¹˜ í¬ê¸° ì¡°ì •**: GPU ë©”ëª¨ë¦¬ì— ë§ê²Œ ì¡°ì •
3. **ì •ê¸°ì ì¸ ì²´í¬í¬ì¸íŠ¸ ì €ì¥**: `--save-every`ë¡œ ì£¼ê¸° ì„¤ì •
4. **ì‹¤í—˜ ì´ë¦„ ì§€ì •**: ì—¬ëŸ¬ ì‹¤í—˜ì„ êµ¬ë¶„í•˜ê¸° ìœ„í•´ ëª…í™•í•œ ì´ë¦„ ì‚¬ìš©
5. **í•™ìŠµë¥  ìŠ¤ì¼€ì¤„ë§**: ëŒ€ë¶€ë¶„ì˜ ê²½ìš° CosineAnnealingLRì´ ì¢‹ì€ ì„±ëŠ¥

---

**Happy Training! ğŸš€** 