{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a66b7fac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class block(nn.Module):\n",
    "    def __init__(self, dim,kernel_size=3, stride=1):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(dim,dim,kernel_size,stride,padding=kernel_size//2)\n",
    "        self.bn1=nn.BatchNorm2d(dim)\n",
    "        self.prelu = nn.PReLU()\n",
    "        self.conv2=nn.Conv2d(dim,dim,kernel_size,stride,padding=kernel_size//2)\n",
    "        self.bn2=nn.BatchNorm2d(dim)\n",
    "        \n",
    "    def forward(self,x):\n",
    "        h1 = self.conv1(x)\n",
    "        bn1 = self.bn1(h1)\n",
    "        prelu1 = self.prelu(bn1)\n",
    "        h2 = self.conv2(prelu1)\n",
    "        bn2 = self.bn2(h2)\n",
    "        out = x+bn2\n",
    "        return out\n",
    "s\n",
    "class PixelShuffle(nn.Module):\n",
    "    def __init__(self, dim, scale, kernel_size):\n",
    "        super().__init__()\n",
    "        self.scale = scale\n",
    "        self.conv = nn.Conv2d(dim, dim * (self.scale**2), kernel_size, padding=kernel_size//2)\n",
    "        self.shuffle = nn.PixelShuffle(self.scale)\n",
    "    def forward(self, x):\n",
    "        h = self.shuffle(self.conv(x))\n",
    "        return h\n",
    "\n",
    "class Generator(nn.Module):\n",
    "    def __init__(self, dim, kernel_size=9, residual_kernel_size=3, stride=1, n_blocks=16):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(dim[0], dim[1], kernel_size, stride=stride, padding=kernel_size//2)\n",
    "        self.prelu1 = nn.PReLU()\n",
    "        \n",
    "        self.residual_blocks = nn.ModuleList()\n",
    "        for _ in range(n_blocks):\n",
    "            self.residual_blocks.append(block(dim[1], residual_kernel_size, stride))\n",
    "        \n",
    "        self.conv2 = nn.Conv2d(dim[1], dim[1], residual_kernel_size, stride, padding=residual_kernel_size//2)\n",
    "        self.bn1 = nn.BatchNorm2d(dim[1])\n",
    "        \n",
    "        \n",
    "        self.upsample = nn.Sequential(\n",
    "           PixelShuffle(dim[1],2, kernel_size=3),\n",
    "           nn.PReLU(),\n",
    "           PixelShuffle(dim[1],2, kernel_size=3),\n",
    "           nn.PReLU()\n",
    "       )\n",
    "     \n",
    "        self.head = nn.Conv2d(dim[1], dim[0],kernel_size, stride, padding=kernel_size//2)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        shallow_feature = self.conv1(x)\n",
    "        shallow_prelu = self.prelu1(shallow_feature)\n",
    "        \n",
    "        residual_out = shallow_prelu\n",
    "        for res_block in self.residual_blocks:\n",
    "            residual_out = res_block(residual_out)\n",
    "        \n",
    "        conv2_out = self.conv2(residual_out)\n",
    "        bn_out = self.bn1(conv2_out)\n",
    "        skip_out = shallow_prelu + bn_out\n",
    "        \n",
    "        upsample_out = self.upsample(skip_out)\n",
    "        \n",
    "        out = self.head(upsample_out)\n",
    "        return out\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d50d173e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, dim=[3,64,128,256,512,1024], kernel_size=3, n_blocks=7):\n",
    "        super().__init__()\n",
    "        self.layers = nn.ModuleList()\n",
    "\n",
    "        # 첫 두 레이어 (stride=1 → stride=2)\n",
    "        self.layers.append(nn.Sequential(\n",
    "            nn.Conv2d(dim[0], dim[1], kernel_size, padding=kernel_size//2),\n",
    "            nn.LeakyReLU(0.2, inplace=True)\n",
    "        ))\n",
    "        self.layers.append(nn.Sequential(\n",
    "            nn.Conv2d(dim[1], dim[1], kernel_size, stride=2, padding=kernel_size//2),\n",
    "            nn.BatchNorm2d(dim[1]),\n",
    "            nn.LeakyReLU(0.2, inplace=True)\n",
    "        ))\n",
    "\n",
    "        # 반복 블록\n",
    "        for i in range(n_blocks-2):\n",
    "            in_c, out_c = dim[i+1], dim[i+2]\n",
    "            stride = 1 if i % 2 == 0 else 2\n",
    "            self.layers.append(nn.Sequential(\n",
    "                nn.Conv2d(in_c, out_c, kernel_size, stride=stride, padding=kernel_size//2),\n",
    "                nn.BatchNorm2d(out_c),\n",
    "                nn.LeakyReLU(0.2, inplace=True)\n",
    "            ))\n",
    "\n",
    "        # 전역 풀링 후 FC로 차원 축소\n",
    "        self.global_pool = nn.AdaptiveAvgPool2d(1)\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(dim[-2], 1024),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Linear(1024, 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        for layer in self.layers:\n",
    "            x = layer(x)\n",
    "\n",
    "        x = self.global_pool(x)          # (B, C, 1, 1)\n",
    "        x = x.view(x.size(0), -1)        # (B, C)\n",
    "        x = self.fc(x)                   # (B, 1)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5e4902c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch pr",
   "language": "python",
   "name": "pypr"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
