{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "import torch.nn.functional as F\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class CA(nn.Module):\n",
        "    def __init__(self, dim, kernel_size, reduction):\n",
        "        super().__init__()\n",
        "        self.conv1 = nn.Conv2d(dim, dim//reduction, kernel_size = kernel_size, stride=1, padding=kernel_size//2)\n",
        "        self.conv2 = nn.Conv2d(dim//reduction, dim, kernel_size = kernel_size, stride =1, padding=kernel_size//2)\n",
        "    def forward(self, x):\n",
        "        g = x.mean([-1,-2], keepdim=True)  # 차원 유지\n",
        "        scaled_g = self.conv1(g)\n",
        "        h = F.relu(scaled_g)\n",
        "        out = self.conv2(h)\n",
        "        return torch.sigmoid(out)\n",
        "    \n",
        "class RCAB(nn.Module):\n",
        "    def __init__(self, dim,kernel_size, stride=1, reduction=16):\n",
        "        super().__init__()\n",
        "        self.conv1 = nn.Conv2d(dim,dim,kernel_size = kernel_size, stride = stride, padding=kernel_size//2)\n",
        "        self.conv2 = nn.Conv2d(dim,dim,kernel_size=kernel_size, stride=stride, padding=kernel_size//2)\n",
        "        self.ca = CA(dim, kernel_size, reduction)\n",
        "    def forward(self, x):\n",
        "        res = self.conv2(F.relu(self.conv1(x)))\n",
        "    \n",
        "        s   = self.ca(res)\n",
        "        res = res * s\n",
        "        \n",
        "        return x + res\n",
        "    \n",
        "class ResidualGroup(nn.Module):\n",
        "    def __init__(self, dim, kernel_size, num_rcab):\n",
        "        super().__init__()\n",
        "        pad = kernel_size // 2\n",
        "        # RCAB 여러 개 + 그룹 내 skip용 conv\n",
        "        modules = [RCAB(dim, kernel_size) for _ in range(num_rcab)]\n",
        "        modules.append(nn.Conv2d(dim, dim, kernel_size, padding=pad))\n",
        "        self.body = nn.Sequential(*modules)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # short skip connection\n",
        "        return x + self.body(x)\n",
        "\n",
        "class RCAN(nn.Module):\n",
        "    def __init__(self, in_channels, n_feats, kernel_size, num_rg, num_rcab, scale):\n",
        "        super().__init__()\n",
        "        pad = kernel_size // 2\n",
        "        # 1) Shallow Feature\n",
        "        self.head = nn.Conv2d(in_channels, n_feats, kernel_size, padding=pad)\n",
        "\n",
        "        # 2) RIR: Residual-in-Residual\n",
        "        self.RIR = nn.ModuleList([\n",
        "            ResidualGroup(n_feats, kernel_size, num_rcab)\n",
        "            for _ in range(num_rg)\n",
        "        ])\n",
        "        # 그룹 전체 skip을 위한 conv\n",
        "        self.conv_after_RIR = nn.Conv2d(n_feats, n_feats, kernel_size, padding=pad)\n",
        "\n",
        "        # 3) Upsample (ESPCN)\n",
        "        self.upsample = nn.Sequential(\n",
        "            nn.Conv2d(n_feats, n_feats * (scale ** 2), kernel_size, padding=pad),\n",
        "            nn.PixelShuffle(scale)\n",
        "        )\n",
        "\n",
        "        # 4) Reconstruction\n",
        "        self.tail = nn.Conv2d(n_feats, in_channels, kernel_size, padding=pad)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # shallow feature\n",
        "        f1 = self.head(x)\n",
        "\n",
        "        # deep feature via RIR\n",
        "        res = f1\n",
        "        for rg in self.RIR:\n",
        "            res = rg(res)\n",
        "        res = self.conv_after_RIR(res)\n",
        "\n",
        "        # long skip + upsample + reconstruct\n",
        "        f2  = self.upsample(f1 + res)\n",
        "        out = self.tail(f2)\n",
        "        return out\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
